# âš¡ Aula 3: "Async Programming Mastery" - Concurrency Deep Dive

**MÃ³dulo 1 - Aula 3 | DuraÃ§Ã£o: 90min | NÃ­vel: TÃ©cnico BÃ¡sico++**

---

## ğŸ¯ **Objetivos de Aprendizagem**

Ao final desta aula, vocÃª serÃ¡ capaz de:
- âœ… Dominar event loops e async/await fundamentalmente
- âœ… Debugar cÃ³digo async como um expert
- âœ… Evitar todos os pitfalls comuns de async programming
- âœ… Otimizar performance de cÃ³digo concurrent

---

## ğŸ”„ **PARTE 1: Event Loop Mastery** (30min)

### ğŸ§  **Async Programming Mental Model**

#### **ğŸ­ Analogia: Restaurante com 1 GarÃ§om Eficiente**

```python
# ğŸš« SYNC (GarÃ§om ineficiente):
def sync_waiter():
    order1 = take_order_customer1()    # 2min waiting
    cook1 = cook_food(order1)          # 15min waiting  
    serve1 = serve_customer1(cook1)    # 1min
    
    order2 = take_order_customer2()    # 2min waiting
    cook2 = cook_food(order2)          # 15min waiting
    serve2 = serve_customer2(cook2)    # 1min
    
    # Total: 36min for 2 customers ğŸ˜±

# âœ… ASYNC (GarÃ§om inteligente):
async def async_waiter():
    # Starts both orders simultaneously
    order1_task = asyncio.create_task(take_order_customer1())
    order2_task = asyncio.create_task(take_order_customer2())
    
    # While orders cook, can do other things
    cook1_task = asyncio.create_task(cook_food(await order1_task))
    cook2_task = asyncio.create_task(cook_food(await order2_task))
    
    # Serve when ready
    await serve_customer1(await cook1_task)
    await serve_customer2(await cook2_task)
    
    # Total: 18min for 2 customers ğŸš€ (50% faster!)
```

### ğŸ”¬ **Event Loop Internals Deep Dive**

#### **âš™ï¸ Como o Event Loop Realmente Funciona**

```python
# ğŸ§ª SimulaÃ§Ã£o do Event Loop (simplificado)
import asyncio
import time
from collections import deque

class SimpleEventLoop:
    """SimulaÃ§Ã£o educacional do asyncio event loop."""
    
    def __init__(self):
        self.ready_queue = deque()      # Tasks prontos para executar
        self.waiting_tasks = {}         # Tasks esperando I/O
        self.time_heap = []            # Tasks com sleep/timeout
        self.running = False
        
    def call_soon(self, callback):
        """Schedule callback para prÃ³xima iteraÃ§Ã£o."""
        self.ready_queue.append(callback)
        
    def call_later(self, delay, callback):
        """Schedule callback apÃ³s delay."""
        when = time.time() + delay
        self.time_heap.append((when, callback))
        self.time_heap.sort()  # Maintain order
        
    def run_once(self):
        """Single iteration of event loop."""
        # 1. Execute ready tasks
        while self.ready_queue:
            task = self.ready_queue.popleft()
            try:
                task()
            except Exception as e:
                print(f"Task error: {e}")
        
        # 2. Check timed tasks
        now = time.time()
        while self.time_heap and self.time_heap[0][0] <= now:
            _, callback = self.time_heap.pop(0)
            self.ready_queue.append(callback)
            
        # 3. Check I/O (simplified - just sleep)
        if not self.ready_queue and not self.time_heap:
            return False  # Nothing to do
        
        return True
    
    def run_until_complete(self, coro):
        """Run coroutine until completion."""
        self.running = True
        task = asyncio.ensure_future(coro)
        
        while not task.done() and self.running:
            if not self.run_once():
                break
                
        return task.result() if task.done() else None

# ğŸ¯ Real asyncio internals:
import asyncio

def analyze_event_loop():
    """Analyze current event loop."""
    loop = asyncio.get_event_loop()
    print(f"Loop type: {type(loop).__name__}")
    print(f"Running: {loop.is_running()}")
    print(f"Closed: {loop.is_closed()}")
    print(f"Debug mode: {loop.get_debug()}")
    
    # Policy analysis
    policy = asyncio.get_event_loop_policy()
    print(f"Policy: {type(policy).__name__}")
```

#### **ğŸš€ asyncio.run() vs Manual Loop Management**

```python
import asyncio
import time

# âœ… Modern approach (Python 3.7+)
async def modern_async():
    await asyncio.sleep(0.1)
    return "Modern way"

result1 = asyncio.run(modern_async())
print(f"Result: {result1}")

# ğŸ”§ Manual loop management (when needed)
async def manual_async():
    await asyncio.sleep(0.1)  
    return "Manual way"

# Get or create loop
try:
    loop = asyncio.get_running_loop()
    # We're already in async context
    result2 = await manual_async()
except RuntimeError:
    # No loop running, create one
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        result2 = loop.run_until_complete(manual_async())
    finally:
        loop.close()

# ğŸ¯ When to use manual approach:
# 1. Custom event loop policies
# 2. Integration with other event loops (Qt, GTK)
# 3. Advanced debugging scenarios
# 4. Library development
```

### âš¡ **anyio vs asyncio - Universal Async**

#### **ğŸŒ Why anyio in Claude SDK**

```python
# âŒ asyncio-only approach:
import asyncio

async def asyncio_only_query():
    """Locked to asyncio - limits compatibility."""
    await asyncio.sleep(1)  # Only works with asyncio
    # SDK would only work in asyncio applications

# âœ… anyio approach (used in SDK):
import anyio

async def universal_query():
    """Works with any async backend."""
    await anyio.sleep(1)  # Works with asyncio, trio, curio
    # SDK works in ANY async application!

# ğŸ¯ Real-world impact:
# Web frameworks using different backends:
# - FastAPI (asyncio)
# - Quart (asyncio) 
# - Trio-based apps
# - Curio applications
# All can use Claude SDK without issues!
```

#### **ğŸ”¬ Backend Comparison**

```python
import time
import anyio

async def backend_benchmark():
    """Compare performance across backends."""
    
    async def cpu_bound_task():
        # Simulate some work
        await anyio.sleep(0.001)
        return sum(range(1000))
    
    backends = ['asyncio', 'trio']
    
    for backend in backends:
        print(f"\nğŸ§ª Testing {backend}:")
        
        start_time = time.time()
        
        async def run_tasks():
            # Run 100 concurrent tasks
            async with anyio.create_task_group() as tg:
                for _ in range(100):
                    tg.start_soon(cpu_bound_task)
        
        try:
            anyio.run(run_tasks, backend=backend)
            duration = time.time() - start_time
            print(f"   Duration: {duration:.3f}s")
            print(f"   Tasks/sec: {100/duration:.1f}")
        except ImportError:
            print(f"   {backend} not available")

# Run comparison
if __name__ == "__main__":
    anyio.run(backend_benchmark)
```

---

## ğŸ§ª **PARTE 2: Common Async Pitfalls & Solutions** (30min)

### ğŸš¨ **Pitfall 1: Blocking the Event Loop**

#### **âŒ Problem Code**
```python
import asyncio
import time
import requests  # Sync library

async def bad_example():
    """DON'T DO THIS - blocks event loop!"""
    print("Starting bad async function...")
    
    # ğŸš« BLOCKING OPERATION in async function
    response = requests.get("https://httpbin.org/delay/2")  # 2s block!
    
    print("This will only run after 2s of BLOCKING")
    return response.json()

# Result: Event loop is completely blocked for 2 seconds
# Other async tasks cannot run during this time!
```

#### **âœ… Solution Code**
```python
import asyncio
import aiohttp  # Async HTTP library

async def good_example():
    """Proper async HTTP - non-blocking."""
    print("Starting good async function...")
    
    # âœ… NON-BLOCKING async operation
    async with aiohttp.ClientSession() as session:
        async with session.get("https://httpbin.org/delay/2") as response:
            print("Other tasks can run while waiting!")
            return await response.json()

# Result: Event loop continues serving other tasks while waiting
```

#### **ğŸ”§ Advanced Solution: Thread Pool for Sync Code**
```python
import asyncio
import requests
import concurrent.futures

async def hybrid_solution():
    """When you MUST use sync libraries in async code."""
    
    # âœ… Run blocking code in thread pool
    loop = asyncio.get_event_loop()
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # This runs in separate thread - doesn't block event loop
        response = await loop.run_in_executor(
            executor, 
            requests.get, 
            "https://httpbin.org/delay/2"
        )
        
    print("Event loop stayed responsive!")
    return response.json()

# ğŸ¯ Use cases:
# - Legacy sync libraries 
# - File I/O operations
# - CPU-intensive computations
# - Database queries with sync drivers
```

### ğŸš¨ **Pitfall 2: asyncio.run() in Running Loop**

#### **âŒ Problem Scenario**
```python
import asyncio

async def inner_task():
    return "Hello from inner"

async def problematic_function():
    """This will fail in Jupyter/existing async context."""
    
    # ğŸš« WILL CRASH if already in async context
    result = asyncio.run(inner_task())  # RuntimeError!
    return result

# Common in:
# - Jupyter notebooks
# - FastAPI endpoints  
# - Other async applications
```

#### **âœ… Universal Solution**
```python
import asyncio
import anyio

async def smart_function():
    """Works in ANY context - async or sync."""
    
    try:
        # Check if we're in async context
        loop = asyncio.get_running_loop()
        # We're already async - just await
        result = await inner_task()
    except RuntimeError:
        # No loop running - safe to use anyio.run
        result = await anyio.run(inner_task)
        
    return result

# Even smarter - detect context automatically:
async def ultra_smart_function():
    """Automatic context detection."""
    import inspect
    
    if inspect.iscoroutinefunction(inner_task):
        # We know it's a coroutine
        try:
            # Try direct await (fastest)
            return await inner_task()
        except RuntimeError:
            # Fallback to anyio
            return await anyio.run(inner_task)
    else:
        # Regular function call
        return inner_task()
```

### ğŸš¨ **Pitfall 3: Forgotten await**

#### **âŒ Common Mistakes**
```python
import asyncio

async def async_operation():
    await asyncio.sleep(1)
    return "Done"

async def mistake_demo():
    """Common await mistakes."""
    
    # ğŸš« MISTAKE 1: Missing await
    result1 = async_operation()  # Returns coroutine object!
    print(type(result1))  # <class 'coroutine'>
    print(result1)        # <coroutine object async_operation at 0x...>
    
    # ğŸš« MISTAKE 2: await on non-async function
    def sync_func():
        return "sync result"
    
    # result2 = await sync_func()  # SyntaxError!
    
    # âœ… CORRECT usage
    result3 = await async_operation()  # Actual result
    print(result3)  # "Done"

# ğŸ” Detection tools:
import warnings

def detect_forgotten_awaits():
    """Enable warnings for unawaited coroutines."""
    warnings.simplefilter('always', RuntimeWarning)
    
    # This will trigger warning:
    async def test():
        async_operation()  # Warning: coroutine never awaited
    
    asyncio.run(test())
```

#### **âœ… Best Practices for Avoiding Mistakes**

```python
import asyncio
from typing import Awaitable, Union

# ğŸ› ï¸ Type hints help catch mistakes
async def type_safe_function(data: str) -> str:
    """Clear async function signature."""
    result = await async_operation()  # Type checker ensures await
    return f"Processed: {data} -> {result}"

# ğŸ”§ Wrapper for sync/async compatibility  
def smart_await(obj: Union[Awaitable, object]):
    """Handle both sync and async objects."""
    if asyncio.iscoroutine(obj):
        # It's async - need to await in async context
        return obj
    else:
        # It's sync - return directly
        return obj

# ğŸ§ª Testing with proper async setup
import pytest

@pytest.mark.asyncio
async def test_async_function():
    """Proper async testing."""
    result = await async_operation()
    assert result == "Done"

# ğŸ¯ Development tools:
# 1. mypy for type checking
# 2. pylint async warnings
# 3. pytest-asyncio for testing
# 4. IDE async/await highlighting
```

---

## ğŸ” **PARTE 3: Debugging Async Code Like a Pro** (30min)

### ğŸ› ï¸ **Advanced Debugging Tools**

#### **ğŸ”¬ Event Loop Debugging**
```python
import asyncio
import logging
import time

# Enable debug mode
asyncio.get_event_loop().set_debug(True)

# Configure logging for asyncio
logging.basicConfig(level=logging.DEBUG)
asyncio_logger = logging.getLogger('asyncio')

async def debug_demo():
    """Demonstrate debugging techniques."""
    
    # 1. Task tracking
    print("Current tasks:")
    for task in asyncio.all_tasks():
        print(f"  Task: {task.get_name()} - {task}")
    
    # 2. Slow callback detection
    async def slow_callback():
        time.sleep(0.1)  # Blocking operation - will be detected!
        
    await slow_callback()
    
    # 3. Memory usage tracking
    import gc
    import sys
    
    tasks_count = len(asyncio.all_tasks())
    memory_usage = sys.getsizeof(gc.get_objects())
    print(f"Tasks: {tasks_count}, Memory objects: {len(gc.get_objects())}")

# Run with debugging
asyncio.run(debug_demo())
```

#### **ğŸ“Š Performance Profiling**
```python
import asyncio
import time
import cProfile
import pstats

async def profile_async_code():
    """Profile async code performance."""
    
    async def cpu_bound_async():
        # Simulate CPU work
        await asyncio.sleep(0)  # Yield control
        return sum(range(10000))
    
    async def io_bound_async():
        # Simulate I/O wait
        await asyncio.sleep(0.1)
        return "IO complete"
    
    # Profile with cProfile
    profiler = cProfile.Profile()
    profiler.enable()
    
    # Run concurrent tasks
    results = await asyncio.gather(
        *[cpu_bound_async() for _ in range(100)],
        *[io_bound_async() for _ in range(10)]
    )
    
    profiler.disable()
    
    # Analyze results
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)  # Top 10 functions

# Advanced profiling with custom metrics
class AsyncProfiler:
    """Custom async performance profiler."""
    
    def __init__(self):
        self.task_stats = {}
        self.start_times = {}
        
    def start_task_timing(self, task_name: str):
        """Start timing a task."""
        self.start_times[task_name] = time.time()
        
    def end_task_timing(self, task_name: str):
        """End timing and record stats."""
        if task_name in self.start_times:
            duration = time.time() - self.start_times[task_name]
            
            if task_name not in self.task_stats:
                self.task_stats[task_name] = []
            
            self.task_stats[task_name].append(duration)
            del self.start_times[task_name]
    
    def report(self):
        """Generate performance report."""
        print("ğŸ” ASYNC PERFORMANCE REPORT")
        print("=" * 40)
        
        for task_name, durations in self.task_stats.items():
            avg_duration = sum(durations) / len(durations)
            min_duration = min(durations)
            max_duration = max(durations)
            
            print(f"ğŸ“Š {task_name}:")
            print(f"   Calls: {len(durations)}")
            print(f"   Avg: {avg_duration:.4f}s")
            print(f"   Min: {min_duration:.4f}s") 
            print(f"   Max: {max_duration:.4f}s")
            print()

# Usage example
profiler = AsyncProfiler()

async def profiled_function():
    profiler.start_task_timing("database_query")
    await asyncio.sleep(0.05)  # Simulate DB query
    profiler.end_task_timing("database_query")
    
    profiler.start_task_timing("api_call")
    await asyncio.sleep(0.1)   # Simulate API call
    profiler.end_task_timing("api_call")

async def run_profiling():
    # Run multiple times for statistics
    await asyncio.gather(*[profiled_function() for _ in range(10)])
    profiler.report()
```

### ğŸ”§ **Debugging Tools for Claude SDK**

#### **ğŸ¯ SDK-Specific Debugging**
```python
import asyncio
import logging
from src import ClaudeSDKClient, query

# Configure logging for Claude SDK debugging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Enable specific loggers
claude_logger = logging.getLogger('claude_sdk')
subprocess_logger = logging.getLogger('asyncio.subprocess')

async def debug_claude_sdk():
    """Debug Claude SDK operations."""
    
    print("ğŸ” DEBUGGING CLAUDE SDK")
    print("=" * 30)
    
    # 1. Connection debugging
    client = ClaudeSDKClient()
    
    try:
        print("ğŸ“¡ Connecting to Claude...")
        await client.connect()
        print("âœ… Connection successful")
        
        # 2. Query debugging with timing
        start_time = time.time()
        await client.query("What is 2+2?")
        
        print("ğŸ“¨ Processing response...")
        async for message in client.receive_response():
            duration = time.time() - start_time
            print(f"â±ï¸  Message received after {duration:.3f}s")
            print(f"ğŸ“„ Message type: {type(message).__name__}")
            
            if hasattr(message, 'content'):
                print(f"ğŸ“ Content blocks: {len(message.content)}")
                
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await client.disconnect()
        print("ğŸ”Œ Disconnected")

# Memory leak detection for long-running applications
import gc
import weakref

class MemoryDebugger:
    """Detect memory leaks in async code."""
    
    def __init__(self):
        self.tracked_objects = []
        
    def track_object(self, obj, name: str):
        """Track object for memory leaks."""
        weak_ref = weakref.ref(obj, lambda ref: self._on_object_deleted(name))
        self.tracked_objects.append((weak_ref, name))
        
    def _on_object_deleted(self, name: str):
        """Called when tracked object is garbage collected."""
        print(f"ğŸ—‘ï¸  Object deleted: {name}")
        
    def check_leaks(self):
        """Check for potential memory leaks."""
        alive_objects = []
        for weak_ref, name in self.tracked_objects:
            if weak_ref() is not None:
                alive_objects.append(name)
        
        if alive_objects:
            print(f"âš ï¸  Potential leaks: {alive_objects}")
        else:
            print("âœ… No memory leaks detected")

# Usage
memory_debugger = MemoryDebugger()

async def test_memory_leaks():
    """Test for memory leaks in Claude SDK usage."""
    
    for i in range(10):
        client = ClaudeSDKClient()
        memory_debugger.track_object(client, f"client_{i}")
        
        await client.connect()
        await client.disconnect()
        
        # Force garbage collection
        del client
        gc.collect()
    
    # Check for leaks
    memory_debugger.check_leaks()
```

---

## ğŸ§ª **EXERCÃCIOS PRÃTICOS**

### **ğŸ¯ ExercÃ­cio 1: Event Loop Mastery (25min)**

**Objetivo:** Implementar custom event loop scheduler

```python
import asyncio
import time
from typing import List, Callable

class SmartScheduler:
    """
    Implemente um scheduler inteligente que:
    1. Prioriza tasks I/O-bound vs CPU-bound
    2. Detecta tasks lentas automaticamente  
    3. Balanceia carga entre tasks
    """
    
    def __init__(self):
        self.io_tasks = []
        self.cpu_tasks = []
        self.slow_tasks = []
        
    async def schedule_task(self, task, task_type: str = "auto"):
        """
        Schedule task com tipo automÃ¡tico ou manual.
        Implemente a lÃ³gica de classificaÃ§Ã£o!
        """
        # TODO: Implementar classificaÃ§Ã£o automÃ¡tica
        # TODO: Detectar tasks lentas (> 100ms)
        # TODO: Balancear execuÃ§Ã£o
        pass
    
    async def run_scheduled_tasks(self):
        """Execute tasks de acordo com prioridades."""
        # TODO: Implementar algoritmo de scheduling
        pass

# Teste seu scheduler:
async def test_scheduler():
    scheduler = SmartScheduler()
    
    # Tasks de diferentes tipos
    async def io_task():
        await asyncio.sleep(0.1)  # I/O simulation
        return "IO done"
    
    async def cpu_task():
        sum(range(100000))  # CPU work
        return "CPU done"
        
    # Schedule e execute
    await scheduler.schedule_task(io_task())
    await scheduler.schedule_task(cpu_task())
    await scheduler.run_scheduled_tasks()

# Execute e meÃ§a performance!
```

### **ğŸ¯ ExercÃ­cio 2: Async Debugging Detective (20min)**

**Problema:** CÃ³digo com mÃºltiplos bugs async

```python
import asyncio
import aiohttp

# ğŸš¨ CÃ“DIGO COM BUGS - ENCONTRE E CORRIJA TODOS!
class BuggyAsyncCode:
    def __init__(self):
        self.data = []
    
    async def fetch_data(self, urls):
        """Fetch data from multiple URLs - HAS BUGS!"""
        
        # Bug 1: Blocking operation
        import requests
        for url in urls:
            response = requests.get(url)  # BUG!
            self.data.append(response.json())
        
        # Bug 2: Missing await
        result = self.process_data()  # BUG!
        return result
    
    def process_data(self):  # Bug 3: Should be async?
        """Process collected data."""
        if not self.data:
            return None
        return {"processed": len(self.data)}
    
    async def run_analysis(self):
        """Main analysis function."""
        urls = [
            "https://httpbin.org/json",
            "https://httpbin.org/uuid", 
            "https://httpbin.org/ip"
        ]
        
        # Bug 4: Exception not handled
        result = await self.fetch_data(urls)
        
        # Bug 5: Incorrect loop usage
        loop = asyncio.get_event_loop()
        final_result = loop.run_until_complete(
            self.additional_processing(result)
        )  # BUG!
        
        return final_result
    
    async def additional_processing(self, data):
        """Additional async processing."""
        await asyncio.sleep(0.1)
        return {"final": data, "timestamp": time.time()}

# Tarefa: Corrija TODOS os bugs e execute sem erros!
```

### **ğŸ¯ ExercÃ­cio 3: Performance Optimization Challenge (25min)**

**Objetivo:** Otimizar cÃ³digo async para mÃ¡xima performance

```python
import asyncio
import aiohttp
import time

# ğŸš€ DESAFIO: Otimize este cÃ³digo para ser 10x mais rÃ¡pido!

class SlowAsyncProcessor:
    """Processor that needs optimization."""
    
    async def slow_fetch(self, url: str) -> dict:
        """Fetch single URL - muito lento!"""
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                await asyncio.sleep(0.1)  # Simula processamento lento
                return await response.json()
    
    async def slow_process_batch(self, urls: List[str]) -> List[dict]:
        """Process URLs sequencialmente - muito lento!"""
        results = []
        for url in urls:
            result = await self.slow_fetch(url)
            results.append(result)
        return results
    
    async def slow_analysis(self, data: List[dict]) -> dict:
        """Analyze data - ineficiente!"""
        analysis = {"total": len(data)}
        
        # Processamento sequencial lento
        for item in data:
            await asyncio.sleep(0.01)  # Simula anÃ¡lise lenta
            if "uuid" in str(item):
                analysis["has_uuid"] = True
                
        return analysis

# TAREFA: Reimplemente como FastAsyncProcessor
class FastAsyncProcessor:
    """Sua versÃ£o otimizada aqui!"""
    
    async def fast_fetch(self, url: str) -> dict:
        # TODO: Otimize esta funÃ§Ã£o
        pass
    
    async def fast_process_batch(self, urls: List[str]) -> List[dict]:
        # TODO: Use concurrency inteligente
        pass
    
    async def fast_analysis(self, data: List[dict]) -> dict:
        # TODO: ParalelizaÃ§Ã£o de anÃ¡lise
        pass

# Benchmark - meta: 10x improvement!
async def benchmark():
    urls = ["https://httpbin.org/uuid"] * 20
    
    # Test slow version
    slow = SlowAsyncProcessor()
    start = time.time()
    slow_result = await slow.slow_process_batch(urls)
    slow_analysis = await slow.slow_analysis(slow_result)
    slow_time = time.time() - start
    
    # Test fast version  
    fast = FastAsyncProcessor()
    start = time.time()
    fast_result = await fast.fast_process_batch(urls)
    fast_analysis = await fast.fast_analysis(fast_result)
    fast_time = time.time() - start
    
    improvement = slow_time / fast_time
    print(f"Improvement: {improvement:.1f}x faster!")
    print(f"Goal: 10x+ improvement")
```

---

## ğŸ“ **RESUMO & PRÃ“XIMOS PASSOS**

### **ğŸ§  Key Takeaways**

1. **ğŸ”„ Event loops** sÃ£o single-threaded cooperativos
2. **âš¡ anyio** oferece compatibilidade universal  
3. **ğŸš¨ Common pitfalls** tÃªm soluÃ§Ãµes conhecidas
4. **ğŸ” Debugging async** requer ferramentas especÃ­ficas

### **ğŸ“ˆ PreparaÃ§Ã£o para Aula 4**

**PrÃ³xima aula:** "Message Flow Analysis - Data Structures"
**Pre-work:**
- Execute todos exercÃ­cios async
- Profile um projeto pessoal com AsyncProfiler

### **ğŸ’¡ QuestÃµes AvanÃ§adas**

1. Como vocÃª implementaria rate limiting em cÃ³digo async?
2. Qual seria sua estratÃ©gia para testing de cÃ³digo async?
3. Como otimizaria async code para mÃ¡xima concurrency sem race conditions?

---

## ğŸ”— **Recursos TÃ©cnicos**

- **ğŸ“– Docs:** [Python asyncio documentation](https://docs.python.org/3/library/asyncio.html)
- **ğŸ› ï¸ Tools:** [AsyncProfiler implementation](../src/tools/profiler.py)
- **ğŸ“Š Benchmark:** [Performance benchmark](../scripts/performance_benchmark.py)
- **ğŸ¯ Next:** [Message Flow Analysis](curso_modulo_01_aula_04.md)

---

**ğŸ¯ PrÃ³xima Aula:** Message Flow Analysis - Data Structures Deep Dive
**ğŸ“… DuraÃ§Ã£o:** 50min | **ğŸ“Š NÃ­vel:** TÃ©cnico BÃ¡sico+++