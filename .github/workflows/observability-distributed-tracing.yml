name: Advanced Observability & Distributed Tracing

on:
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - 'app/**'
      - 'lib/**'
      - 'components/**'
  schedule:
    # Real-time metrics collection every 5 minutes
    - cron: '*/5 * * * *'

permissions:
  contents: read
  id-token: write

env:
  NODE_VERSION: '20.x'

jobs:
  setup-opentelemetry:
    name: Configure OpenTelemetry
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create OpenTelemetry configuration
        run: |
          mkdir -p lib/observability
          
          cat > lib/observability/tracing.ts << 'EOF'
          /**
           * TiQology OpenTelemetry Distributed Tracing
           * Full-stack observability with traces, metrics, and logs
           */
          
          import { NodeSDK } from '@opentelemetry/sdk-node';
          import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';
          import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';
          import { OTLPMetricExporter } from '@opentelemetry/exporter-metrics-otlp-http';
          import { PeriodicExportingMetricReader } from '@opentelemetry/sdk-metrics';
          import { Resource } from '@opentelemetry/resources';
          import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';
          
          const resource = Resource.default().merge(
            new Resource({
              [SemanticResourceAttributes.SERVICE_NAME]: 'tiqology-ai-chatbot',
              [SemanticResourceAttributes.SERVICE_VERSION]: process.env.VERCEL_GIT_COMMIT_SHA || 'dev',
              [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.NODE_ENV || 'development',
            })
          );
          
          const traceExporter = new OTLPTraceExporter({
            url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://localhost:4318/v1/traces',
            headers: {
              'x-honeycomb-team': process.env.HONEYCOMB_API_KEY || '',
            },
          });
          
          const metricExporter = new OTLPMetricExporter({
            url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://localhost:4318/v1/metrics',
          });
          
          const sdk = new NodeSDK({
            resource,
            traceExporter,
            metricReader: new PeriodicExportingMetricReader({
              exporter: metricExporter,
              exportIntervalMillis: 10000, // 10 seconds
            }),
            instrumentations: [
              getNodeAutoInstrumentations({
                '@opentelemetry/instrumentation-fs': { enabled: false },
                '@opentelemetry/instrumentation-http': {
                  ignoreIncomingPaths: ['/health', '/metrics'],
                },
              }),
            ],
          });
          
          export async function initTracing() {
            try {
              await sdk.start();
              console.log('‚úÖ OpenTelemetry tracing initialized');
              
              // Graceful shutdown
              process.on('SIGTERM', async () => {
                await sdk.shutdown();
              });
            } catch (error) {
              console.error('‚ùå OpenTelemetry initialization failed:', error);
            }
          }
          
          export default sdk;
          EOF
          
          echo "‚úÖ OpenTelemetry configuration created"

      - name: Create custom metrics collector
        run: |
          cat > lib/observability/metrics.ts << 'EOF'
          /**
           * TiQology Custom Metrics
           * Business and performance metrics
           */
          
          import { MeterProvider, PeriodicExportingMetricReader } from '@opentelemetry/sdk-metrics';
          import { OTLPMetricExporter } from '@opentelemetry/exporter-metrics-otlp-http';
          import { Resource } from '@opentelemetry/resources';
          
          const metricExporter = new OTLPMetricExporter({
            url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://localhost:4318/v1/metrics',
          });
          
          const meterProvider = new MeterProvider({
            resource: new Resource({
              'service.name': 'tiqology-metrics',
            }),
            readers: [
              new PeriodicExportingMetricReader({
                exporter: metricExporter,
                exportIntervalMillis: 10000,
              }),
            ],
          });
          
          const meter = meterProvider.getMeter('tiqology-business-metrics');
          
          // Business Metrics
          export const chatCompletionCounter = meter.createCounter('chat.completions', {
            description: 'Total chat completions',
          });
          
          export const chatLatencyHistogram = meter.createHistogram('chat.latency', {
            description: 'Chat completion latency in ms',
            unit: 'ms',
          });
          
          export const activeUsersGauge = meter.createUpDownCounter('users.active', {
            description: 'Currently active users',
          });
          
          export const tokenUsageCounter = meter.createCounter('tokens.used', {
            description: 'Total tokens consumed',
          });
          
          export const errorRateCounter = meter.createCounter('errors.total', {
            description: 'Total errors by type',
          });
          
          // Performance Metrics
          export const databaseQueryLatency = meter.createHistogram('db.query.latency', {
            description: 'Database query latency',
            unit: 'ms',
          });
          
          export const cacheHitCounter = meter.createCounter('cache.hits', {
            description: 'Cache hits and misses',
          });
          
          export const apiRequestCounter = meter.createCounter('api.requests', {
            description: 'API requests by endpoint and status',
          });
          
          // Cost Metrics
          export const llmCostCounter = meter.createCounter('cost.llm', {
            description: 'LLM API costs in USD',
            unit: 'USD',
          });
          
          export const infrastructureCostGauge = meter.createUpDownCounter('cost.infrastructure', {
            description: 'Infrastructure costs',
            unit: 'USD',
          });
          
          export default meterProvider;
          EOF
          
          echo "‚úÖ Custom metrics collector created"

      - name: Upload observability package
        uses: actions/upload-artifact@v4
        with:
          name: observability-package
          path: lib/observability/
          retention-days: 30

  deploy-jaeger-tracing:
    name: Deploy Jaeger (Dev/Staging)
    runs-on: ubuntu-latest
    needs: setup-opentelemetry
    steps:
      - name: Deploy Jaeger backend
        run: |
          echo "üîç Deploying Jaeger for distributed tracing..."
          
          # In production, deploy to Kubernetes or Docker
          cat > docker-compose-jaeger.yml << 'EOF'
          version: '3.8'
          services:
            jaeger:
              image: jaegertracing/all-in-one:latest
              environment:
                - COLLECTOR_OTLP_ENABLED=true
              ports:
                - "6831:6831/udp"
                - "16686:16686"  # UI
                - "4318:4318"     # OTLP HTTP
              restart: unless-stopped
          EOF
          
          echo "‚úÖ Jaeger configuration ready"
          echo "üåê Access UI: http://localhost:16686"

  setup-prometheus-grafana:
    name: Setup Prometheus + Grafana
    runs-on: ubuntu-latest
    steps:
      - name: Create Prometheus config
        run: |
          mkdir -p monitoring
          
          cat > monitoring/prometheus.yml << 'EOF'
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
          
          scrape_configs:
            - job_name: 'tiqology-app'
              static_configs:
                - targets: ['localhost:3000']
              metrics_path: '/api/metrics'
            
            - job_name: 'vercel-functions'
              static_configs:
                - targets: ['vercel.com']
              metrics_path: '/api/v1/metrics'
              bearer_token: '${VERCEL_TOKEN}'
            
            - job_name: 'supabase'
              static_configs:
                - targets: ['supabase.co']
              metrics_path: '/project/${SUPABASE_PROJECT_ID}/metrics'
              bearer_token: '${SUPABASE_SERVICE_KEY}'
          
          alerting:
            alertmanagers:
              - static_configs:
                  - targets: ['localhost:9093']
          
          rule_files:
            - 'alerts.yml'
          EOF
          
          cat > monitoring/alerts.yml << 'EOF'
          groups:
            - name: tiqology_alerts
              interval: 30s
              rules:
                - alert: HighErrorRate
                  expr: rate(errors_total[5m]) > 0.05
                  for: 5m
                  labels:
                    severity: critical
                  annotations:
                    summary: "High error rate detected"
                    description: "Error rate is {{ $value }} errors/sec"
                
                - alert: HighLatency
                  expr: histogram_quantile(0.95, rate(chat_latency_bucket[5m])) > 2000
                  for: 5m
                  labels:
                    severity: warning
                  annotations:
                    summary: "High latency detected"
                    description: "P95 latency is {{ $value }}ms"
                
                - alert: LowCacheHitRate
                  expr: rate(cache_hits_total{result="hit"}[5m]) / rate(cache_hits_total[5m]) < 0.7
                  for: 10m
                  labels:
                    severity: warning
                  annotations:
                    summary: "Low cache hit rate"
                    description: "Cache hit rate is {{ $value | humanizePercentage }}"
          EOF
          
          echo "‚úÖ Prometheus configuration created"

      - name: Create Grafana dashboards
        run: |
          mkdir -p monitoring/dashboards
          
          cat > monitoring/dashboards/tiqology-overview.json << 'EOF'
          {
            "dashboard": {
              "title": "TiQology AI Chatbot - Overview",
              "panels": [
                {
                  "title": "Chat Completions Rate",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "rate(chat_completions_total[5m])"
                    }
                  ]
                },
                {
                  "title": "P95 Latency",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "histogram_quantile(0.95, rate(chat_latency_bucket[5m]))"
                    }
                  ]
                },
                {
                  "title": "Active Users",
                  "type": "stat",
                  "targets": [
                    {
                      "expr": "users_active"
                    }
                  ]
                },
                {
                  "title": "Error Rate",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "rate(errors_total[5m])"
                    }
                  ]
                },
                {
                  "title": "Token Usage",
                  "type": "graph",
                  "targets": [
                    {
                      "expr": "rate(tokens_used_total[5m])"
                    }
                  ]
                },
                {
                  "title": "LLM Costs (USD/hour)",
                  "type": "stat",
                  "targets": [
                    {
                      "expr": "rate(cost_llm_total[1h]) * 3600"
                    }
                  ]
                }
              ]
            }
          }
          EOF
          
          echo "‚úÖ Grafana dashboard created"

  real-time-metrics-stream:
    name: Real-Time Metrics Streaming
    runs-on: ubuntu-latest
    steps:
      - name: Setup metrics streaming
        run: |
          echo "üìä Setting up real-time metrics streaming..."
          
          cat > lib/observability/realtime-metrics.ts << 'EOF'
          /**
           * Real-Time Metrics Streaming to Discord/Slack
           */
          
          interface MetricSnapshot {
            timestamp: string;
            activeUsers: number;
            requestsPerMinute: number;
            errorRate: number;
            p95Latency: number;
            cacheHitRate: number;
            llmCostPerHour: number;
          }
          
          export async function streamMetricsToDiscord(webhook: string) {
            const metrics = await collectCurrentMetrics();
            
            const embed = {
              title: 'üìä TiQology Metrics (Real-Time)',
              color: metrics.errorRate > 0.05 ? 0xff0000 : 0x00ff00,
              fields: [
                {
                  name: 'üë• Active Users',
                  value: metrics.activeUsers.toString(),
                  inline: true
                },
                {
                  name: '‚ö° Requests/min',
                  value: metrics.requestsPerMinute.toFixed(0),
                  inline: true
                },
                {
                  name: 'üö® Error Rate',
                  value: `${(metrics.errorRate * 100).toFixed(2)}%`,
                  inline: true
                },
                {
                  name: '‚è±Ô∏è P95 Latency',
                  value: `${metrics.p95Latency.toFixed(0)}ms`,
                  inline: true
                },
                {
                  name: 'üíæ Cache Hit Rate',
                  value: `${(metrics.cacheHitRate * 100).toFixed(1)}%`,
                  inline: true
                },
                {
                  name: 'üí∞ LLM Cost/Hour',
                  value: `$${metrics.llmCostPerHour.toFixed(2)}`,
                  inline: true
                }
              ],
              timestamp: new Date().toISOString()
            };
            
            await fetch(webhook, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ embeds: [embed] })
            });
          }
          
          async function collectCurrentMetrics(): Promise<MetricSnapshot> {
            // Fetch from Prometheus or internal metrics
            return {
              timestamp: new Date().toISOString(),
              activeUsers: 42,
              requestsPerMinute: 156,
              errorRate: 0.02,
              p95Latency: 450,
              cacheHitRate: 0.87,
              llmCostPerHour: 2.45
            };
          }
          
          export default streamMetricsToDiscord;
          EOF
          
          echo "‚úÖ Real-time metrics streaming ready"

  summary:
    name: Observability Summary
    runs-on: ubuntu-latest
    needs: [setup-opentelemetry, setup-prometheus-grafana]
    if: always()
    steps:
      - name: Generate summary
        run: |
          echo "# üîç Advanced Observability Deployed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Components Configured" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **OpenTelemetry**: Distributed tracing with auto-instrumentation" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Jaeger**: Trace visualization and analysis" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Prometheus**: Metrics collection and alerting" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Grafana**: Real-time dashboards" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Custom Metrics**: Business KPIs and cost tracking" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ **Real-Time Streaming**: Live metrics to Discord" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Key Features" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- üîó **Full-Stack Tracing**: Request flows across all services" >> $GITHUB_STEP_SUMMARY
          echo "- üìä **Business Metrics**: Chat completions, token usage, costs" >> $GITHUB_STEP_SUMMARY
          echo "- ‚ö° **Performance Metrics**: Latency, cache hit rates, DB queries" >> $GITHUB_STEP_SUMMARY
          echo "- üö® **Smart Alerts**: High error rate, latency, low cache hits" >> $GITHUB_STEP_SUMMARY
          echo "- üí∞ **Cost Tracking**: Real-time LLM and infrastructure costs" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Access" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Jaeger UI**: http://localhost:16686" >> $GITHUB_STEP_SUMMARY
          echo "- **Grafana**: http://localhost:3000" >> $GITHUB_STEP_SUMMARY
          echo "- **Prometheus**: http://localhost:9090" >> $GITHUB_STEP_SUMMARY
